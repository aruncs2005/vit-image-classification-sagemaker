{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker Training jobs demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Preparing Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Install Required dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install datasets transformers\n",
    "! pip install -U sagemaker boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preperaing Dataset\n",
    "\n",
    "For this example we will be using Food 101 dataset which originally contains 76k samples of food images comprising of 101 labels. For this run we will limit the number of samples to 11k with 10k used for training and 1k used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "\n",
    "# Load a dataset Let's start by loading a small image classification dataset and taking a look at its structure\n",
    "ds = DatasetDict()\n",
    "ds[\"train\"] = load_dataset('food101',split=\"train\")\n",
    "ds[\"validation\"] = load_dataset('food101',split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dataset to S3 for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_input_path = f's3://{sess.default_bucket()}/dataset/food101'\n",
    "print(f\"training dataset to: {training_input_path}\")# save train_dataset to s3\n",
    "ds.save_to_disk(training_input_path)\n",
    "\n",
    "print(f\"uploaded data to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run training on SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "\n",
    "# change the model name/path here to switch between resnet: \"microsoft/resnet-101\" and vit: \"google/vit-base-patch16-224-in21k\" \n",
    "#hyperparameters[\"model_name_or_path\"] = \"microsoft/resnet-101\"\n",
    "hyperparameters[\"model_name_or_path\"] = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "hyperparameters[\"seed\"] = 100\n",
    "hyperparameters[\"per_device_train_batch_size\"] = 128\n",
    "hyperparameters[\"per_device_eval_batch_size\"] = 128\n",
    "hyperparameters[\"learning_rate\"] = 5e-5\n",
    "\n",
    "hyperparameters[\"max_train_steps\"] = 10000 # use 10000\n",
    "hyperparameters[\"num_train_epochs\"] = 25\n",
    "hyperparameters[\"output_dir\"] = \"/opt/ml/model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensorboard configuration\n",
    "\n",
    "output_path = os.path.join(\n",
    "   \"s3://\"+sagemaker_session_bucket, \"sagemaker-output\", \"01102024\", \"vit-img-classification-ddp\"\n",
    ")\n",
    "LOG_DIR = \"/opt/ml/output/tensorboard\"\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path=os.path.join(output_path, 'tensorboard'),\n",
    "    container_local_output_path=LOG_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiler configuration\n",
    "\n",
    "from sagemaker import ProfilerConfig, Profiler\n",
    "profiler_config = ProfilerConfig(\n",
    "    profile_params = Profiler(cpu_profiling_duration=3600)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_job_name=\"vit-img-classification-ddp\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    base_job_name=base_job_name,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point= \"train_ddp.py\",\n",
    "    role=role,\n",
    "    image_uri=\"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.0.0-gpu-py310-cu118-ubuntu20.04-sagemaker\",\n",
    "    #framework_version=\"2.0.0\",\n",
    "    #py_version=\"py310\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4de.24xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution={ \"pytorchddp\": { \"enabled\": True } },\n",
    "    keep_alive_period_in_seconds=900,\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    profiler_config=profiler_config,\n",
    "    disable_output_compression=True,\n",
    "    enable_remote_debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit({\"train\":training_input_path},wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ssh to the nodes use the below command\n",
    "# aws ssm start-session --target sagemaker-training-job:<training_job_name>_algo-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
